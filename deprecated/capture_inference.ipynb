{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOpcUoZDfTCO"
   },
   "source": [
    "# BerryBox Berry Segmentation\n",
    "\n",
    "## Run inferencing using a trained YOLOv8 model\n",
    "\n",
    "This notebook is meant to be run on a Windows PC using a CPU\n",
    "\n",
    "THIS NOTEBOOK IS FOR CAPTURING IMAGING AND RUNNING THE INFERENCE PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Install depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHUelLBQfTCR"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Open ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project directory and change directory\n",
    "import os\n",
    "import shutil\n",
    "proj_dir = os.getcwd()\n",
    "proj_dir\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import a YOLO model and export it using OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the model\n",
    "# model_path = os.path.join(proj_dir, \"models/berrybox_best_20240316.pt\")\n",
    "model_path = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/Repositories/berryboxai/models/berrybox_inst_seg_nano_best_20240318.pt\"\n",
    "# OpenVino model path\n",
    "ov_model_path = \"../models/\" + os.path.basename(model_path).replace(\".pt\", \"_openvino_model\")\n",
    "\n",
    "# Attempt to find the openvino version of the model;\n",
    "# If it does not exist, export the model\n",
    "if not os.path.exists(ov_model_path):\n",
    "\n",
    "    # Copy the model locally\n",
    "    model_path_local = os.path.join(\"models\", os.path.basename(model_path))\n",
    "    shutil.copyfile(model_path, model_path_local)\n",
    "\n",
    "    # Load the model with YOLO\n",
    "    from ultralytics import YOLO\n",
    "    model = YOLO(model_path_local)\n",
    "\n",
    "    # Export the model using openVINO\n",
    "    # model.export(format = \"openvino\", imgsz = 2048, half = True)\n",
    "    model.export(format = \"openvino\", imgsz = (1344, 2016), half = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouQnM_MufTCT"
   },
   "source": [
    "2. Import dependecies, set parameters\n",
    "Note: Make sure functions.py is in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7UIPkIHfTCT"
   },
   "outputs": [],
   "source": [
    "from functions import * # load all functions\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "gc.collect()   # collect garbage\n",
    "\n",
    "device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Directories\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_dir = ov_model_path # path to the model\n",
    "image_dir = 'images' # path to the image folder\n",
    "save_dir = 'output' # path to save the results\n",
    "\n",
    "# shutil.rmtree(save_dir, ignore_errors=True)\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Model Parameters (you can change these parameters to suit your needs)\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_params = {\n",
    "    'project': save_dir, # project name\n",
    "    'name': \"berrybox_\" + os.path.basename(proj_dir), # run name\n",
    "    'save': False, # save image results\n",
    "    'show_labels': True,   # hide labels\n",
    "    'show_conf': True, # hide confidences\n",
    "    'save_crop': False, # save cropped prediction boxes\n",
    "    'line_width': 3, # bounding box line width\n",
    "    'conf': 0.70, # confidence threshold\n",
    "    'iou': 0.75, # NMS IoU threshold\n",
    "    # 'imgsz': 2048,\n",
    "    'imgsz': (1344, 2016),\n",
    "    # 'imgsz': (640, 960),\n",
    "    'exist_ok': False, # if True, it overwrites current 'name' saving folder\n",
    "    'half': True, # use FP16 half-precision inference True/False\n",
    "    'cache': False, # use cache images for faster inference\n",
    "    'retina_masks': False, #use high resolution seg mask\n",
    "    'device': device, # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_dir, task = \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76h-1YCtfTCU"
   },
   "source": [
    "3. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running inference and extracting features...')\n",
    "\n",
    "# Create an empty pandas data frame\n",
    "DF = pd.DataFrame()\n",
    "\n",
    "# List images in the image dir\n",
    "image_files = [x for x in os.listdir(image_dir) if \".JPG\" or \".PNG\" in x.upper()]\n",
    "# Target model size\n",
    "newH, newW = model_params[\"imgsz\"]\n",
    "\n",
    "# Iterate over the image files\n",
    "for i, img_name in enumerate(image_files):\n",
    "    \n",
    "    # Read in the image and resize\n",
    "    image = Image.open(image_dir + \"/\" + img_name).resize((newW, newH))\n",
    "    \n",
    "    # Run through the model\n",
    "    results = model.predict(source = image, **model_params)\n",
    "    result = results[0]\n",
    "\n",
    "    # Process the results\n",
    "    # Try color correction; skip if it doesn't work\n",
    "    try:\n",
    "        result, patch_size = color_correction(result)\n",
    "    except:\n",
    "        continue\n",
    "    # Was \"info\" found?\n",
    "    if any(result.boxes.cls == get_ids(result, 'info')[0]):\n",
    "        QR_info = read_QR_code(result)\n",
    "    else:\n",
    "        print(\"No 'info' detected by the model.\\n\")\n",
    "        QR_info = img_name\n",
    "    # Get features\n",
    "    df1 = get_all_features_parallel(result, name= 'berry')\n",
    "    df2 = get_all_features_parallel(result, name= 'rotten')\n",
    "    df = pd.concat([pd.DataFrame({'name': (['berry'] * df1.shape[0]) + (['rotten'] * df2.shape[0])}), pd.concat([df1, df2], ignore_index = True)], axis = 1)    \n",
    "    w,_ = df.shape\n",
    "    img_name = [img_name]*w\n",
    "    QR_info = [QR_info]*w\n",
    "    patch_size = [np.mean(patch_size)]*w\n",
    "    indeces = list(range(w))\n",
    "    # If indeces is length 0; warn that no berries were found\n",
    "    if len(indeces) == 0:\n",
    "        print('\\033[1;33mNo berries were found in the image!\\033[0m')\n",
    "        continue\n",
    "\n",
    "    df_fore = pd.DataFrame({'Image_name': img_name,\n",
    "                            'ID': indeces,\n",
    "                            'QR_info': QR_info,\n",
    "                            'Patch_size': patch_size})\n",
    "\n",
    "    df = pd.concat([df_fore, df], axis=1)\n",
    "    DF = pd.concat([DF, df], axis=0, ignore_index=True)\n",
    "\n",
    "    img_save_folder = os.path.join(save_dir, 'predictions')\n",
    "    if not os.path.exists(img_save_folder):\n",
    "        os.makedirs(img_save_folder)\n",
    "\n",
    "    save_ROI_parallel(result, get_ids(result, 'berry'), os.path.join(img_save_folder, img_name[0]))\n",
    "\n",
    "    print(f\"\\nImage {i+1} of {len(image_files)} processed.\" )\n",
    "    \n",
    "    \n",
    "DF.to_csv(os.path.join(save_dir, 'features.csv'), index=False)\n",
    "print('Done.')\n",
    "\n",
    "gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
