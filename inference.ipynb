{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOpcUoZDfTCO"
   },
   "source": [
    "# BerryBox Berry Segmentation\n",
    "\n",
    "## Run inferencing using a trained YOLOv8 model\n",
    "\n",
    "This notebook is meant to be run on a Windows PC using a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.186  Python-3.9.18 torch-2.2.1+cpu CPU (Intel Core(TM) i7-10810U 1.10GHz)\n",
      "Setup complete  (12 CPUs, 31.6 GB RAM, 421.1/951.3 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 5E84-0237\n",
      "\n",
      " Directory of c:\\Users\\jeffrey.neyhart\\OneDrive - USDA\\Documents\\CranberryLab\\Breeding\\2021\\Imaging\\BerryBoxImaging\n",
      "\n",
      "05/10/2024  11:28 AM    <DIR>          .\n",
      "05/10/2024  11:28 AM    <DIR>          ..\n",
      "03/17/2024  03:42 PM    <DIR>          .ipynb_checkpoints\n",
      "05/10/2024  11:24 AM    <DIR>          __pycache__\n",
      "12/29/2022  11:40 AM             2,696 data_cleanup.R\n",
      "05/10/2024  11:42 AM            14,183 functions.py\n",
      "03/17/2024  05:56 PM    <DIR>          images\n",
      "05/10/2024  11:42 AM            21,322 inference.ipynb\n",
      "05/10/2024  11:24 AM    <DIR>          models\n",
      "05/10/2024  11:32 AM    <DIR>          output\n",
      "03/19/2024  11:40 AM    <DIR>          output1\n",
      "11/22/2022  10:27 AM               464 REAMDE.txt\n",
      "03/17/2024  04:41 PM                79 requirements.txt\n",
      "               5 File(s)         38,744 bytes\n",
      "               8 Dir(s)  569,249,898,496 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Open ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "# Set project directory and change directory\n",
    "import os\n",
    "import shutil\n",
    "proj_dir = os.getcwd()\n",
    "proj_dir\n",
    "%ls\n",
    "\n",
    "# Model inference size\n",
    "image_size = (1856, 2784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import a YOLO model and export it using OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the model\n",
    "model_path = os.path.join(proj_dir, \"models/berrybox_inst_seg_nano_best_20240324.pt\")\n",
    "# model_path = \"C:/Users/jeffrey.neyhart/Documents/Phenomics/berryboxai/models/berrybox_inst_seg_nano_best_20240324.pt\"\n",
    "# OpenVino model path\n",
    "ov_model_path = model_path.replace(\".pt\", \"_openvino_model\")\n",
    "\n",
    "# Attempt to find the openvino version of the model;\n",
    "# If it does not exist, export the model\n",
    "if not os.path.exists(ov_model_path):\n",
    "\n",
    "    os.chdir(os.path.dirname(model_path))\n",
    "\n",
    "    # Copy the model to the OpenVino location \n",
    "    model_path_local = model_path\n",
    "\n",
    "    # Load the model with YOLO\n",
    "    from ultralytics import YOLO\n",
    "    model = YOLO(model_path_local)\n",
    "\n",
    "    # Export the model using openVINO\n",
    "    model.export(format = \"openvino\", imgsz = image_size, half = True)\n",
    "\n",
    "    os.chdir(proj_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouQnM_MufTCT"
   },
   "source": [
    "2. Import dependecies, set parameters\n",
    "Note: Make sure functions.py is in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e7UIPkIHfTCT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from functions import * # load all functions\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "gc.collect()   # collect garbage\n",
    "\n",
    "device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Directories\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_dir = ov_model_path # path to the model\n",
    "image_dir = 'images' # path to the image folder\n",
    "save_dir = 'output' # path to save the results\n",
    "\n",
    "# shutil.rmtree(save_dir, ignore_errors=True)\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Model Parameters (you can change these parameters to suit your needs)\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_params = {\n",
    "    'project': save_dir, # project name\n",
    "    'name': \"berrybox_\" + os.path.basename(proj_dir), # run name\n",
    "    'save': False, # save image results\n",
    "    'show_labels': True,   # hide labels\n",
    "    'show_conf': True, # hide confidences\n",
    "    'save_crop': False, # save cropped prediction boxes\n",
    "    'line_width': 3, # bounding box line width\n",
    "    'conf': 0.70, # confidence threshold\n",
    "    'iou': 0.75, # NMS IoU threshold\n",
    "    'imgsz': image_size,\n",
    "    'exist_ok': True, # if True, it overwrites current 'name' saving folder\n",
    "    'half': True, # use FP16 half-precision inference True/False\n",
    "    'cache': False, # use cache images for faster inference\n",
    "    'retina_masks': False, #use high resolution seg mask\n",
    "    'device': device, # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_dir, task = \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76h-1YCtfTCU"
   },
   "source": [
    "3. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference and extracting features for 2 images...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading c:\\Users\\jeffrey.neyhart\\OneDrive - USDA\\Documents\\CranberryLab\\Breeding\\2021\\Imaging\\BerryBoxImaging\\models\\berrybox_inst_seg_nano_best_20240324_openvino_model for OpenVINO inference...\n",
      "\n",
      "0: 1856x2784 1 ColorCard, 41 berrys, 1 info, 4117.8ms\n",
      "Speed: 126.7ms preprocess, 4117.8ms inference, 3934.4ms postprocess per image at shape (1, 3, 1856, 2784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Color correcting the image...\n",
      "\n",
      "Initial mean DeltaE:  7.70943872417\n",
      "Number of components:  10\n",
      "\n",
      "Color correction complete.\n",
      "\n",
      "\n",
      "Reading QR code...\n",
      "\n",
      "\n",
      "QR code reading complete.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "Extracting features: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 of 2 processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1856x2784 1 ColorCard, 41 berrys, 1 info, 994.7ms\n",
      "Speed: 76.7ms preprocess, 994.7ms inference, 2586.0ms postprocess per image at shape (1, 3, 1856, 2784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Color correcting the image...\n",
      "\n",
      "Initial mean DeltaE:  7.39397356979\n",
      "Number of components:  10\n",
      "\n",
      "Color correction complete.\n",
      "\n",
      "\n",
      "Reading QR code...\n",
      "\n",
      "\n",
      "QR code reading complete.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 41/41 [00:10<00:00,  4.01it/s]\n",
      "Extracting features: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 of 2 processed.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty pandas data frame\n",
    "DF = pd.DataFrame()\n",
    "\n",
    "# List images in the image dir\n",
    "image_files = [x for x in os.listdir(image_dir) if \".JPG\" in x.upper() or \".PNG\" in x.upper()]\n",
    "\n",
    "# Print the number of images\n",
    "print('Running inference and extracting features for ' + str(len(image_files)) + \" images...\\n\")\n",
    "\n",
    "# Target model size\n",
    "newH, newW = model_params[\"imgsz\"]\n",
    "\n",
    "# Iterate over the image files\n",
    "for i, img_name in enumerate(image_files):\n",
    "    \n",
    "    # Read in the image and resize\n",
    "    image = Image.open(image_dir + \"/\" + img_name).resize((newW, newH))\n",
    "    \n",
    "    # Run through the model\n",
    "    results = model.predict(source = image, **model_params)\n",
    "    result = results[0]\n",
    "\n",
    "    # Process the results\n",
    "    # Try color correction; skip if it doesn't work\n",
    "    try:\n",
    "        result, patch_size = color_correction(result)\n",
    "    except:\n",
    "        continue\n",
    "    # Was \"info\" found?\n",
    "    if any(result.boxes.cls == get_ids(result, 'info')[0]):\n",
    "        QR_info = read_QR_code(result)\n",
    "    else:\n",
    "        print(\"No 'info' detected by the model.\\n\")\n",
    "        QR_info = img_name\n",
    "    # Get features\n",
    "    df1 = get_all_features_parallel(result, name= 'berry')\n",
    "    df2 = get_all_features_parallel(result, name= 'rotten')\n",
    "    df = pd.concat([pd.DataFrame({'name': (['berry'] * df1.shape[0]) + (['rotten'] * df2.shape[0])}), pd.concat([df1, df2], ignore_index = True)], axis = 1)    \n",
    "    w,_ = df.shape\n",
    "    img_name = [img_name]*w\n",
    "    QR_info = [QR_info]*w\n",
    "    patch_size = [np.mean(patch_size)]*w\n",
    "    indeces = list(range(w))\n",
    "    # If indeces is length 0; warn that no berries were found\n",
    "    if len(indeces) == 0:\n",
    "        print('\\033[1;33mNo berries were found in the image!\\033[0m')\n",
    "        continue\n",
    "\n",
    "    df_fore = pd.DataFrame({'Image_name': img_name,\n",
    "                            'ID': indeces,\n",
    "                            'QR_info': QR_info,\n",
    "                            'Patch_size': patch_size})\n",
    "\n",
    "    df = pd.concat([df_fore, df], axis=1)\n",
    "    DF = pd.concat([DF, df], axis=0, ignore_index=True)\n",
    "\n",
    "    img_save_folder = os.path.join(save_dir, 'predictions')\n",
    "    if not os.path.exists(img_save_folder):\n",
    "        os.makedirs(img_save_folder)\n",
    "\n",
    "    save_ROI_parallel(result, get_ids(result, 'berry'), os.path.join(img_save_folder, img_name[0]))\n",
    "\n",
    "    print(f\"\\nImage {i+1} of {len(image_files)} processed.\" )\n",
    "    \n",
    "    \n",
    "DF.to_csv(os.path.join(save_dir, 'features.csv'), index=False)\n",
    "print('Done.')\n",
    "\n",
    "gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
