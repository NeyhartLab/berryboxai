{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOpcUoZDfTCO"
   },
   "source": [
    "# BerryBox Berry Segmentation\n",
    "\n",
    "## Run inferencing using a trained YOLOv8 model\n",
    "\n",
    "This notebook is meant to be run on a Windows PC using a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "# Set project directory and change directory\n",
    "import os\n",
    "import shutil\n",
    "proj_dir = os.getcwd()\n",
    "proj_dir\n",
    "%ls\n",
    "\n",
    "# Model inference size\n",
    "image_size = (1856, 2784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import a YOLO model and export it using OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the model\n",
    "# model_path = os.path.join(proj_dir, \"models/berrybox_inst_seg_nano_best_20240324.pt\")\n",
    "model_path = \"C:/Users/jeffrey.neyhart/Documents/Phenomics/berryboxai/models/berrybox_inst_seg_nano_best_20240324.pt\"\n",
    "# OpenVino model path\n",
    "ov_model_path = model_path.replace(\".pt\", \"_openvino_model\")\n",
    "\n",
    "# Attempt to find the openvino version of the model;\n",
    "# If it does not exist, export the model\n",
    "if not os.path.exists(ov_model_path):\n",
    "\n",
    "    os.chdir(os.path.dirname(model_path))\n",
    "\n",
    "    # Copy the model to the OpenVino location \n",
    "    model_path_local = model_path\n",
    "\n",
    "    # Load the model with YOLO\n",
    "    from ultralytics import YOLO\n",
    "    model = YOLO(model_path_local)\n",
    "\n",
    "    # Export the model using openVINO\n",
    "    model.export(format = \"openvino\", imgsz = image_size, half = True)\n",
    "\n",
    "    os.chdir(proj_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouQnM_MufTCT"
   },
   "source": [
    "2. Import dependecies, set parameters\n",
    "Note: Make sure functions.py is in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e7UIPkIHfTCT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from functions import * # load all functions\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "gc.collect()   # collect garbage\n",
    "\n",
    "device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Directories\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_dir = ov_model_path # path to the model\n",
    "image_dir = 'images' # path to the image folder\n",
    "save_dir = 'output' # path to save the results\n",
    "\n",
    "# shutil.rmtree(save_dir, ignore_errors=True)\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------\n",
    "Set Model Parameters (you can change these parameters to suit your needs)\n",
    "------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "model_params = {\n",
    "    'project': save_dir, # project name\n",
    "    'name': \"berrybox_\" + os.path.basename(proj_dir), # run name\n",
    "    'save': False, # save image results\n",
    "    'show_labels': True,   # hide labels\n",
    "    'show_conf': True, # hide confidences\n",
    "    'save_crop': False, # save cropped prediction boxes\n",
    "    'line_width': 3, # bounding box line width\n",
    "    'conf': 0.70, # confidence threshold\n",
    "    'iou': 0.75, # NMS IoU threshold\n",
    "    'imgsz': image_size,\n",
    "    'exist_ok': True, # if True, it overwrites current 'name' saving folder\n",
    "    'half': True, # use FP16 half-precision inference True/False\n",
    "    'cache': False, # use cache images for faster inference\n",
    "    'retina_masks': False, #use high resolution seg mask\n",
    "    'device': device, # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_dir, task = \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76h-1YCtfTCU"
   },
   "source": [
    "3. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_inference(input_dir = image_dir, output_dir = save_dir, params = model_params, model = model)\n",
    "\n",
    "gc.collect()    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
